import os
import re
import yaml
import sys
import json
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# .envã®èª­ã¿è¾¼ã¿
load_dotenv()

# Windowså¯¾å¿œ
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

def generate_corrections(text_path):
    api_key = os.environ.get("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    
    try:
        with open(text_path, 'r', encoding='utf-8') as f:
            full_text = f.read()
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    print(f"ðŸ” æœ€å¼·è¾žæ›¸ï¼ˆå…¨æ–‡ã‚¹ã‚­ãƒ£ãƒ³ï¼‰ã‚’ä½œæˆä¸­: {Path(text_path).name} ...")
    
    # ãƒ†ã‚­ã‚¹ãƒˆé‡ãŒå¤šã„å ´åˆã¯ã€é‡è¦ãªç®‡æ‰€ï¼ˆæœ€åˆãƒ»ä¸­é–“ãƒ»æœ€å¾Œï¼‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦AIã«æ¸¡ã™
    # ã¾ãŸã¯å…¨æ–‡ã‚’æŠ•ã’ã‚‹ï¼ˆä»Šå›žã¯3k-4kæ–‡å­—ç¨‹åº¦ã¾ã§ã‚’æƒ³å®šï¼‰
    content_sample = full_text[:4000] 

    prompt = f"""
ä»¥ä¸‹ã®å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã€TTSï¼ˆéŸ³å£°åˆæˆï¼‰ã®èª­ã¿é–“é•ã„ã‚’é˜²ããŸã‚ã®ã€Œå®Œç’§ãªèª­ã¿è¾žæ›¸ã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ†ã‚­ã‚¹ãƒˆã«ç™»å ´ã™ã‚‹ã€Œã™ã¹ã¦ã®æ¼¢å­—ã‚’å«ã‚€å˜èªžï¼ˆç†Ÿèªžã€åå‰ã€ä¸€èˆ¬åè©žï¼‰ã€ã‚’æŠ½å‡ºã—ã€æ­£ã—ã„èª­ã¿ï¼ˆã²ã‚‰ãŒãªï¼‰ã‚’JSONã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
1. ç™»å ´äººç‰©ã®åå‰ï¼ˆé»’å´Žã€èŠ±éŸ³ãªã©ï¼‰ãªã©ã®å›ºæœ‰åè©žã€‚
2. ã€Œè‚‰è¦ªã€ã€Œå®ç‰©ã€ã€Œæ–™ç†äººã€ã€Œæ¶™ã€ãªã©ã®ä¸€èˆ¬åè©žã€‚
3. æ•°å­—ã‚’å«ã‚€è¡¨ç¾ï¼ˆ17æ­³ã€280æ­³ã€1å¹´é–“ãªã©ï¼‰ã€‚
4. èª­ã¿ãŒè¤‡æ•°ã‚ã‚‹æ¼¢å­—ã‚„ã€AIãŒé–“é•ãˆã‚„ã™ã„ç†Ÿèªžã™ã¹ã¦ã€‚

å‡ºåŠ›å½¢å¼: JSON {{ "å˜èªž": "ã‚ˆã¿" }}

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{content_sample}
---
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o", # æŠ½å‡ºç²¾åº¦ã‚’ä¸Šã’ã‚‹ãŸã‚ 4o ã‚’ä½¿ç”¨
            messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç·¨é›†è€…ã§ã™ã€‚"},
                      {"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        
        corrections = json.loads(response.choices[0].message.content)
        
        filename_stem = Path(text_path).stem
        title = re.sub(r'^\d{8}_', '', filename_stem)
        
        # æ€§åˆ¥åˆ¤å®š
        gender_res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ä¸»äººå…¬ã®æ€§åˆ¥ã‚’ 'male' ã¾ãŸã¯ 'female' ã§ç­”ãˆã¦ãã ã•ã„ã€‚"},
                      {"role": "user", "content": content_sample[:1000]}],
        )
        gender = gender_res.choices[0].message.content.strip().lower()
        suggested_voice = "fable" if "male" in gender else "nova"

        yaml_data = {
            "title": title,
            "category": "ç¾å®Ÿä¸–ç•Œ[æ‹æ„›]",
            "voice": suggested_voice,
            "original_date": filename_stem.split('_')[0] if '_' in filename_stem else "",
            "corrections": corrections
        }
        
        yaml_path = Path(text_path).with_suffix('.yaml')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        
        print(f"âœ… æœ€å¼·è¾žæ›¸ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {yaml_path}")
        print(f"   ç™»éŒ²å˜èªžæ•°: {len(corrections)}ä»¶")
            
    except Exception as e:
        print(f"âŒ è§£æžã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        generate_corrections(sys.argv[1])
