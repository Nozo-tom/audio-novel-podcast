import os
import re
import yaml
import sys
import json
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# .envã®èª­ã¿è¾¼ã¿
load_dotenv()

# Windowså¯¾å¿œ
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')


def get_text_analysis_from_ai(client, text_chunk, model="gpt-4o-mini"):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰èª­ã¿é–“é•ã„ãã†ãªå˜èªã‚’AIã«æŠ½å‡ºã•ã›ã‚‹"""
    prompt = f"""
ä»¥ä¸‹ã®å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã€TTSï¼ˆéŸ³å£°åˆæˆï¼‰ãŒèª­ã¿é–“é•ãˆãã†ãª**æ¼¢å­—èªå¥**ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºã™ã¹ãã‚‚ã®ã€‘
1. äººåï¼ˆä½è—¤ç¾å’²â†’ã•ã¨ã†ã¿ã•ãã€è’¼çœŸâ†’ãã†ã¾ ç­‰ï¼‰
2. åœ°åãƒ»æ–½è¨­åï¼ˆç‹ç«‹é­”æ³•å­¦åœ’â†’ãŠã†ã‚Šã¤ã¾ã»ã†ãŒããˆã‚“ ç­‰ï¼‰
3. æ–‡è„ˆã§èª­ã¿ãŒå¤‰ã‚ã‚‹æ¼¢å­—ï¼ˆä¸€äººâ†’ã²ã¨ã‚Šã€ä»Šæ—¥â†’ãã‚‡ã† ç­‰ï¼‰
4. TTSãŒé–“é•ãˆãã†ãªç†Ÿèªï¼ˆå«ŒãŒã‚‰ã›â†’ã„ã‚„ãŒã‚‰ã›ã€å«‰å¦¬â†’ã—ã£ã¨ ç­‰ï¼‰

ã€çµ¶å¯¾ã«ç™»éŒ²ã—ãªã„ã§ãã ã•ã„ã€‘
- ã‚«ã‚¿ã‚«ãƒŠèªï¼ˆãƒªãƒªã‚¢ãƒŠã€ã‚¨ãƒªã‚¶ãƒ™ãƒ¼ãƒˆã€ãƒ†ã‚£ãƒ¼ã‚«ãƒƒãƒ—ç­‰ï¼‰â†’ TTSã¯æ­£ã—ãèª­ã‚ã‚‹
- ã²ã‚‰ãŒãªèª â†’ å¤‰æ›ä¸è¦
- ä¸€èˆ¬çš„ãªæ¼¢å­—ï¼ˆå­¦åœ’ã€é­”æ³•ã€è»¢ç”Ÿã€ç‹å­ã€éƒ¨å±‹ã€å½¼å¥³ã€å®Œç’§ ç­‰ï¼‰â†’ TTSãŒæ­£ã—ãèª­ã‚ã‚‹
- æ•°å­—ï¼ˆäºŒå¹´ç”Ÿã€ä¸‰ãƒ¶æœˆç­‰ï¼‰â†’ TTSãŒæ­£ã—ãèª­ã‚ã‚‹
- å¥èª­ç‚¹ã‚„è¨˜å·ã‚’å«ã‚€ãƒ•ãƒ¬ãƒ¼ã‚º

ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘
- ã‚­ãƒ¼ã¯åŸæ–‡ãƒ†ã‚­ã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹æ¼¢å­—èªå¥ãã®ã¾ã¾ï¼ˆ2æ–‡å­—ä»¥ä¸Šï¼‰
- å€¤ã¯ã²ã‚‰ãŒãªã®ã¿ï¼ˆã‚«ã‚¿ã‚«ãƒŠã‚„æ¼¢å­—ã‚’å«ã¾ãªã„ï¼‰
- æœ¬å½“ã«TTSãŒé–“é•ãˆãã†ãªã‚‚ã®ã ã‘ã«å³é¸ï¼ˆ10ã€œ20ä»¶ç¨‹åº¦ï¼‰

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{text_chunk}
---
å‡ºåŠ›ã¯JSONå½¢å¼ {{ "æ¼¢å­—èªå¥": "ã²ã‚‰ãŒãªã‚ˆã¿" }} ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚
"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": "ã‚ãªãŸã¯TTSèª­ã¿é–“é•ã„é˜²æ­¢ã®å°‚é–€å®¶ã§ã™ã€‚æœ¬å½“ã«é–“é•ãˆãã†ãªã‚‚ã®ã ã‘ã‚’å³é¸ã—ã¦ãã ã•ã„ã€‚"},
                      {"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"âš ï¸ è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼‰: {e}")
        return {}


def generate_corrections(text_path, mode="deep"):
    """
    èª­ã¿æ›¿ãˆè¾æ›¸ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚
    
    mode:
        "basic" - å…ˆé ­6000æ–‡å­—ã®ã¿ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰
        "deep"  - å…ˆé ­ãƒ»ä¸­é–“ãƒ»æœ«å°¾ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‹æ•°å­—è£œå®Œï¼ˆé«˜ç²¾åº¦ï¼‰
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    client = OpenAI(api_key=api_key)
    
    try:
        with open(text_path, 'r', encoding='utf-8') as f:
            full_text = f.read()
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    filename_stem = Path(text_path).stem
    title = re.sub(r'^\d{8}_', '', filename_stem)
    
    print(f"ğŸ” èª­ã¿æ›¿ãˆè¾æ›¸ã‚’ä½œæˆä¸­: {Path(text_path).name}")
    print(f"   ãƒ¢ãƒ¼ãƒ‰: {'ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¹ã‚­ãƒ£ãƒ³' if mode == 'deep' else 'ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚­ãƒ£ãƒ³'}")

    all_corrections = {}

    if mode == "basic":
        # --- basic ãƒ¢ãƒ¼ãƒ‰: å…ˆé ­6000æ–‡å­—ã®ã¿ï¼ˆgpt-4oä½¿ç”¨ï¼‰ ---
        content_sample = full_text[:6000]
        
        prompt = f"""
ä»¥ä¸‹ã®å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã«ç™»å ´ã™ã‚‹ã€Œã™ã¹ã¦ã®æ¼¢å­—ã‚’å«ã‚€å˜èªï¼ˆç†Ÿèªã€å›ºæœ‰åè©ã€ä¸€èˆ¬åè©ã€å‹•è©ã€å½¢å®¹è©ãªã©ï¼‰ã€ã‚’æ¼ã‚‰ã•ãšæŠ½å‡ºã—ã€
ãã®æ­£ã—ã„èª­ã¿ï¼ˆã²ã‚‰ãŒãªï¼‰ã‚’JSONå½¢å¼ã§ãƒªã‚¹ãƒˆåŒ–ã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºã®æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. å°èª¬ã«å‡ºã¦ãã‚‹å…¨ã¦ã®æ¼¢å­—ç†Ÿèªã‚’å¯¾è±¡ã«ã—ã¦ãã ã•ã„ã€‚
2. ç‰¹ã«ä»¥ä¸‹ã®èªå¥ã¯TTSãŒèª­ã¿é–“é•ãˆã‚„ã™ã„ãŸã‚ã€ç¢ºå®Ÿã«å…¥ã‚Œã¦ãã ã•ã„ï¼š
   - å›ºæœ‰åè©ï¼ˆäººåã€åœ°åã€å­¦æ ¡åãªã©ï¼‰
   - æ•°å­—ã¨å˜ä½ï¼ˆ17æ­³ã€280æ­³ã€1å¹´é–“ã€4æœˆã€2å¹´Bçµ„ãªã©ï¼‰
   - æ–‡è„ˆã§èª­ã¿ãŒå¤‰ã‚ã‚‹èªå¥ï¼ˆæ˜¨æ—¥ã€ä»Šæ—¥ã€æ˜æ—¥ã€ä»Šæœã€ååˆ†ãªã©ï¼‰
3. æ´»ç”¨èªï¼ˆå‹•è©ã®é€ã‚Šä»®åä»˜ããªã©ï¼‰ã‚‚ã€èª­ã¿é–“é•ã„ãŒæ‡¸å¿µã•ã‚Œã‚‹ã‚‚ã®ã¯å«ã‚ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼: JSON {{ "æ¼¢å­—": "ã²ã‚‰ãŒãª" }}

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{content_sample}
---
"""
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ ¡æ­£è€…ã§ã™ã€‚"},
                          {"role": "user", "content": prompt}],
                response_format={ "type": "json_object" }
            )
            all_corrections = json.loads(response.choices[0].message.content)
            print(f"   âœ… ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {len(all_corrections)}ä»¶")
        except Exception as e:
            print(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return

    else:
        # --- deep ãƒ¢ãƒ¼ãƒ‰: è¤‡æ•°ç®‡æ‰€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆgpt-4o-miniä½¿ç”¨ï¼‰ ---
        text_samples = []
        chunk_size = 2000
        text_samples.append(full_text[:chunk_size])  # é–‹å§‹
        if len(full_text) > chunk_size * 2:
            text_samples.append(full_text[len(full_text)//2 : len(full_text)//2 + chunk_size])  # ä¸­é–“
        if len(full_text) > chunk_size * 3:
            text_samples.append(full_text[-chunk_size:])  # æœ«å°¾

        print(f"   ğŸ“Š {len(text_samples)}ç®‡æ‰€ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
        for i, sample in enumerate(text_samples):
            print(f"   â³ ã‚µãƒ³ãƒ—ãƒ« {i+1}/{len(text_samples)} ã‚’è§£æä¸­...")
            res = get_text_analysis_from_ai(client, sample)
            all_corrections.update(res)
            print(f"      â†’ {len(res)}ä»¶ æŠ½å‡º")

        print(f"   âœ… ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {len(all_corrections)}ä»¶")
    
    # ===== ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: ä¸è¦ã‚¨ãƒ³ãƒˆãƒªã‚’é™¤å¤– =====
    filtered = {}
    removed = 0
    for key, val in all_corrections.items():
        # ã‚­ãƒ¼ã‹å€¤ãŒæ–‡å­—åˆ—ã§ãªã„ â†’ ã‚¹ã‚­ãƒƒãƒ—
        if not isinstance(key, str) or not isinstance(val, str):
            removed += 1
            continue
        # ã‚­ãƒ¼ãŒ1æ–‡å­— â†’ éƒ¨åˆ†ä¸€è‡´ãƒªã‚¹ã‚¯ãŒé«˜ã„
        if len(key) < 2:
            removed += 1
            continue
        # ã‚­ãƒ¼ãŒã‚«ã‚¿ã‚«ãƒŠã®ã¿ â†’ TTSãŒæ­£ã—ãèª­ã‚ã‚‹
        if re.match(r'^[\u30A0-\u30FFãƒ¼ãƒ»]+$', key):
            removed += 1
            continue
        # ã‚­ãƒ¼ãŒã²ã‚‰ãŒãªã®ã¿ â†’ å¤‰æ›ä¸è¦
        if re.match(r'^[\u3040-\u309F]+$', key):
            removed += 1
            continue
        # ã‚­ãƒ¼ã«æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ â†’ ä¸è¦
        if not re.search(r'[\u4e00-\u9fa5]', key):
            removed += 1
            continue
        # å€¤ã«æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ â†’ ã²ã‚‰ãŒãªèª­ã¿ã˜ã‚ƒãªã„
        if re.search(r'[\u4e00-\u9fa5]', val):
            removed += 1
            continue
        # ã‚­ãƒ¼ãŒåŸæ–‡ã«å­˜åœ¨ã—ãªã„ â†’ ç„¡åŠ¹
        if key not in full_text:
            removed += 1
            continue
        filtered[key] = val
    
    if removed > 0:
        print(f"   ğŸ§¹ {removed}ä»¶ã®ä¸è¦ã‚¨ãƒ³ãƒˆãƒªã‚’é™¤å¤– â†’ {len(filtered)}ä»¶ã«çµã‚Šè¾¼ã¿")
    all_corrections = filtered
    
    # ===== æ€§åˆ¥åˆ¤å®š â†’ éŸ³å£°ãƒ¢ãƒ‡ãƒ«æ¨å¥¨ =====
    print("   ğŸ­ ä¸»äººå…¬ã®æ€§åˆ¥ã‚’åˆ¤å®šä¸­...")
    try:
        gender_res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": """å°èª¬ã®ä¸»äººå…¬ï¼ˆèªã‚Šæ‰‹ãƒ»ä¸€äººç§°è¦–ç‚¹ã®äººç‰©ï¼‰ã®æ€§åˆ¥ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

åˆ¤å®šåŸºæº–:
- ä¸€äººç§°ãŒã€Œä¿ºã€ã€Œåƒ•ã€â†’ ç”·æ€§
- ä¸€äººç§°ãŒã€Œã‚ãŸã—ã€ã€Œã‚ãŸãã—ã€â†’ å¥³æ€§
- ä¸€äººç§°ãŒã€Œç§ã€â†’ æ–‡è„ˆãƒ»åå‰ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ã§åˆ¤æ–­
- ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œä»¤å¬¢ã€ã€Œå§«ã€ã€Œä¹™å¥³ã€ã€Œå¥³ä½“åŒ–ã€â†’ å¥³æ€§ã®å¯èƒ½æ€§ãŒé«˜ã„
- åå‰ï¼ˆå¤ªéƒã€ä»‹ã€ä¿Š = ç”·æ€§ / ç¾å’²ã€èŠ±ã€å­ = å¥³æ€§ï¼‰
- ã€ŒãŠå¬¢æ§˜ã€ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹ â†’ å¥³æ€§

å›ç­”ã¯ 'male' ã‹ 'female' ã®1èªã®ã¿ã€‚"""},
                {"role": "user", "content": f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\n\n{full_text[:2000]}"}
            ],
        )
        gender = gender_res.choices[0].message.content.strip().lower()
        
        if "female" in gender:
            suggested_voice = "nova"
            gender_label = "å¥³æ€§"
        elif "male" in gender:
            suggested_voice = "fable"
            gender_label = "ç”·æ€§"
        else:
            suggested_voice = "nova"
            gender_label = "å¥³æ€§"
        
        print(f"      â†’ ä¸»äººå…¬: {gender_label} â†’ æ¨å¥¨éŸ³å£°: {suggested_voice}")
    except Exception:
        suggested_voice = "fable"
        gender_label = "ä¸æ˜"
        print(f"      â†’ åˆ¤å®šå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°: {suggested_voice}")

    # ===== YAMLä¿å­˜ =====
    yaml_data = {
        "title": title,
        "category": "ç¾å®Ÿä¸–ç•Œ[æ‹æ„›]",
        "voice": suggested_voice,
        "original_date": filename_stem.split('_')[0] if '_' in filename_stem else "",
        "corrections": all_corrections
    }
    
    yaml_path = Path(text_path).with_suffix('.yaml')
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
    
    print(f"\nâœ¨ èª­ã¿æ›¿ãˆè¾æ›¸ãŒå®Œæˆã—ã¾ã—ãŸ: {yaml_path}")
    print(f"   ç™»éŒ²å˜èªæ•°: {len(all_corrections)}ä»¶")
    print(f"   æ¨å¥¨éŸ³å£°: {suggested_voice} ({gender_label}ä¸»äººå…¬)")
    print(f"   ğŸ’¡ éŸ³å£°ã‚’å¤‰æ›´ã—ãŸã„å ´åˆã¯ YAML ã® voice ã‚’æ›¸ãæ›ãˆã¦ãã ã•ã„")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ğŸ“– èª­ã¿æ›¿ãˆè¾æ›¸è‡ªå‹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«",
    )
    parser.add_argument("input", help="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--mode", choices=["basic", "deep"], default="deep",
                        help="ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰: basic(é«˜é€Ÿ) / deep(é«˜ç²¾åº¦, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)")
    
    args = parser.parse_args()
    generate_corrections(args.input, mode=args.mode)
