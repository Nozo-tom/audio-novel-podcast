import os
import re
import yaml
import sys
import json
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# .envã®èª­ã¿è¾¼ã¿
load_dotenv()

# Windowså¯¾å¿œ
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

def generate_corrections(text_path):
    api_key = os.environ.get("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)
    
    try:
        with open(text_path, 'r', encoding='utf-8') as f:
            full_text = f.read()
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return

    print(f"ðŸ” æœ€å¼·è¾žæ›¸ï¼ˆå…¨æ–‡ã‚¹ã‚­ãƒ£ãƒ³ï¼†å…¨æ¼¢å­—æŠ½å‡ºï¼‰ã‚’ä½œæˆä¸­: {Path(text_path).name} ...")
    
    # è§£æžå¯¾è±¡ï¼ˆãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å†…ã§æœ€å¤§åŒ–ï¼‰
    content_sample = full_text[:6000] 

    prompt = f"""
ä»¥ä¸‹ã®å°èª¬ãƒ†ã‚­ã‚¹ãƒˆã«ç™»å ´ã™ã‚‹ã€Œã™ã¹ã¦ã®æ¼¢å­—ã‚’å«ã‚€å˜èªžï¼ˆç†Ÿèªžã€å›ºæœ‰åè©žã€ä¸€èˆ¬åè©žã€å‹•è©žã€å½¢å®¹è©žãªã©ï¼‰ã€ã‚’æ¼ã‚‰ã•ãšæŠ½å‡ºã—ã€
ãã®æ­£ã—ã„èª­ã¿ï¼ˆã²ã‚‰ãŒãªï¼‰ã‚’JSONå½¢å¼ã§ãƒªã‚¹ãƒˆåŒ–ã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºã®æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. å°èª¬ã«å‡ºã¦ãã‚‹å…¨ã¦ã®æ¼¢å­—ç†Ÿèªžã‚’å¯¾è±¡ã«ã—ã¦ãã ã•ã„ã€‚
2. ç‰¹ã«ä»¥ä¸‹ã®èªžå¥ã¯TTSãŒèª­ã¿é–“é•ãˆã‚„ã™ã„ãŸã‚ã€ç¢ºå®Ÿã«å…¥ã‚Œã¦ãã ã•ã„ï¼š
   - ã€Œæ­£ä½“ï¼ˆã—ã‚‡ã†ãŸã„ï¼‰ã€ã€Œæˆäººï¼ˆã›ã„ã˜ã‚“ï¼‰ã€ã€Œè‚‰è¦ªï¼ˆã«ãã—ã‚“ï¼‰ã€ã€Œå®ç‰©ï¼ˆãŸã‹ã‚‰ã‚‚ã®ï¼‰ã€ã€Œæ­»ç¥žï¼ˆã—ã«ãŒã¿ï¼‰ã€ã€Œè¦‹ç¿’ã„ï¼ˆã¿ãªã‚‰ã„ï¼‰ã€
   - å›ºæœ‰åè©žï¼ˆé»’å´Žãƒ¬ã‚¤ã€å±±ç”°èŠ±éŸ³ã€æ¡œãƒ¶ä¸˜é«˜æ ¡ãªã©ï¼‰
   - æ•°å­—ã¨å˜ä½ï¼ˆ17æ­³ã€280æ­³ã€1å¹´é–“ã€4æœˆã€2å¹´Bçµ„ãªã©ï¼‰
   - æ–‡è„ˆã§èª­ã¿ãŒå¤‰ã‚ã‚‹èªžå¥ï¼ˆæ˜¨æ—¥ã€ä»Šæ—¥ã€æ˜Žæ—¥ã€ä»Šæœã€ååˆ†ãªã©ï¼‰
3. æ´»ç”¨èªžï¼ˆå‹•è©žã®é€ã‚Šä»®åä»˜ããªã©ï¼‰ã‚‚ã€èª­ã¿é–“é•ã„ãŒæ‡¸å¿µã•ã‚Œã‚‹ã‚‚ã®ã¯å«ã‚ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼: JSON {{ "æ¼¢å­—": "ã²ã‚‰ãŒãª" }}
â€»ã€Œæ¼¢å­—ã€ã¯æœ¬æ–‡ä¸­ã®è¡¨è¨˜ãã®ã¾ã¾ã€ã€Œã²ã‚‰ãŒãªã€ã¯æ­£ã—ã„èª­ã¿ã®ã¿ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{content_sample}
---
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o", # ç²¾åº¦å„ªå…ˆ
            messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ ¡æ­£è€…ã§ã™ã€‚"},
                      {"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        
        corrections = json.loads(response.choices[0].message.content)
        
        filename_stem = Path(text_path).stem
        title = re.sub(r'^\d{8}_', '', filename_stem)
        
        # æ€§åˆ¥åˆ¤å®š
        gender_res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ä¸»äººå…¬ã®æ€§åˆ¥ã‚’ 'male' ã¾ãŸã¯ 'female' ã§ç­”ãˆã¦ãã ã•ã„ã€‚"},
                      {"role": "user", "content": content_sample[:1000]}],
        )
        gender = gender_res.choices[0].message.content.strip().lower()
        suggested_voice = "fable" if "male" in gender else "nova"

        yaml_data = {
            "title": title,
            "category": "ç¾å®Ÿä¸–ç•Œ[æ‹æ„›]",
            "voice": suggested_voice,
            "original_date": filename_stem.split('_')[0] if '_' in filename_stem else "",
            "corrections": corrections
        }
        
        yaml_path = Path(text_path).with_suffix('.yaml')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        
        print(f"âœ… æœ€å¼·è¾žæ›¸ï¼ˆå…¨ç¶²ç¾…ç‰ˆï¼‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {yaml_path}")
        print(f"   ç™»éŒ²å˜èªžæ•°: {len(corrections)}ä»¶")
            
    except Exception as e:
        print(f"âŒ è§£æžã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        generate_corrections(sys.argv[1])
