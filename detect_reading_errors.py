# =============================================================================
# TTSèª­ã¿é–“é•ã„æ¤œå‡ºãƒ„ãƒ¼ãƒ«
# TTS â†’ Whisperæ–‡å­—èµ·ã“ã— â†’ åŸæ–‡æ¯”è¼ƒã§èª­ã¿é–“é•ã„ã‚’è‡ªå‹•æ¤œå‡º
# =============================================================================

import os
import time
import re
import sys
import tempfile
import difflib
from pathlib import Path

# Windowså¯¾å¿œ: UTF-8å‡ºåŠ›è¨­å®š
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# =============================================================================
# è¨­å®š
# =============================================================================

INPUT_FILE = r"c:\Users\natak\Documents\Novel\ã²ã‚ˆã‚Š01_å…ƒ.txt"
OUTPUT_DIR = r"c:\Users\natak\Documents\Novel"

TTS_MODEL = "tts-1"
TTS_VOICE = "fable"  # ç‰©èªå‘ã‘
MAX_CHUNK_SIZE = 4000
REQUEST_INTERVAL = 0.5

# =============================================================================
# åˆæœŸåŒ–
# =============================================================================

print("\n" + "=" * 70)
print("ğŸ“š TTSèª­ã¿é–“é•ã„æ¤œå‡ºãƒ„ãƒ¼ãƒ«")
print("=" * 70)

# APIã‚­ãƒ¼å–å¾—
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    print("âŒ ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    OPENAI_API_KEY = input("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
    if not OPENAI_API_KEY:
        print("âŒ APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        sys.exit(1)

try:
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("âœ… OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
except ImportError:
    print("âŒ openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("   pip install openai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    sys.exit(1)

# =============================================================================
# ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿
# =============================================================================

print(f"\nğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
print(f"   ãƒ•ã‚¡ã‚¤ãƒ«: {INPUT_FILE}")

encodings_to_try = ['utf-8', 'shift_jis', 'cp932', 'euc-jp']
novel_text = None

for encoding in encodings_to_try:
    try:
        with open(INPUT_FILE, 'r', encoding=encoding) as f:
            novel_text = f.read()
        print(f"âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§èª­ã¿è¾¼ã¿æˆåŠŸ")
        break
    except UnicodeDecodeError:
        continue
    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {INPUT_FILE}")
        sys.exit(1)

if novel_text is None:
    print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    sys.exit(1)

# ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
novel_text = novel_text.strip()
novel_text = re.sub(r'\r\n', '\n', novel_text)
novel_text = re.sub(r'\n{3,}', '\n\n', novel_text)

print(f"ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±: {len(novel_text):,} æ–‡å­—")

# =============================================================================
# ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
# =============================================================================

def split_text_into_chunks(text: str, max_size: int = 4000) -> list:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½å˜ä½ã§åˆ†å‰²"""
    paragraphs = text.split('\n\n')
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        if len(paragraph) > max_size:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = ""
            
            sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', paragraph)
            temp_chunk = ""
            
            for i in range(0, len(sentences), 2):
                sentence = sentences[i]
                if i + 1 < len(sentences):
                    sentence += sentences[i + 1]
                
                if len(temp_chunk) + len(sentence) <= max_size:
                    temp_chunk += sentence
                else:
                    if temp_chunk:
                        chunks.append(temp_chunk.strip())
                    temp_chunk = sentence
            
            if temp_chunk:
                current_chunk = temp_chunk
        else:
            test_chunk = current_chunk + "\n\n" + paragraph if current_chunk else paragraph
            
            if len(test_chunk) <= max_size:
                current_chunk = test_chunk
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

chunks = split_text_into_chunks(novel_text, MAX_CHUNK_SIZE)
total_chars = sum(len(chunk) for chunk in chunks)

print(f"ğŸ“¦ {len(chunks)} ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")

# =============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—1: TTSéŸ³å£°ç”Ÿæˆ
# =============================================================================

print("\n" + "=" * 70)
print("ğŸ™ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: TTSéŸ³å£°ç”Ÿæˆ")
print("=" * 70)

temp_dir = tempfile.mkdtemp()
audio_files = []
processed_chars = 0

for i, chunk in enumerate(chunks):
    output_path = os.path.join(temp_dir, f"chunk_{i+1:03d}.mp3")
    
    try:
        response = client.audio.speech.create(
            model=TTS_MODEL,
            voice=TTS_VOICE,
            input=chunk,
            response_format="mp3"
        )
        response.stream_to_file(output_path)
        audio_files.append(output_path)
        
        processed_chars += len(chunk)
        progress = processed_chars / total_chars * 100
        print(f"   [{i+1}/{len(chunks)}] TTSç”Ÿæˆå®Œäº† ({len(chunk):,}æ–‡å­—) - é€²æ—: {progress:.1f}%")
        
        if i < len(chunks) - 1:
            time.sleep(REQUEST_INTERVAL)
            
    except Exception as e:
        print(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        sys.exit(1)

print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {len(audio_files)} ãƒ•ã‚¡ã‚¤ãƒ«")

# =============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—2: Whisperæ–‡å­—èµ·ã“ã—
# =============================================================================

print("\n" + "=" * 70)
print("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—2: Whisperæ–‡å­—èµ·ã“ã—")
print("=" * 70)

transcribed_texts = []

for i, audio_path in enumerate(audio_files):
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ja",
                response_format="text"
            )
        
        transcribed_texts.append(transcript)
        progress = (i + 1) / len(audio_files) * 100
        print(f"   [{i+1}/{len(audio_files)}] æ–‡å­—èµ·ã“ã—å®Œäº† - é€²æ—: {progress:.1f}%")
        
        if i < len(audio_files) - 1:
            time.sleep(REQUEST_INTERVAL)
            
    except Exception as e:
        print(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {i+1} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        transcribed_texts.append("")

print(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {len(transcribed_texts)} ãƒãƒ£ãƒ³ã‚¯")

# =============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—3: å·®åˆ†æ¯”è¼ƒãƒ»èª­ã¿é–“é•ã„æ¤œå‡º
# =============================================================================

print("\n" + "=" * 70)
print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: èª­ã¿é–“é•ã„æ¤œå‡º")
print("=" * 70)

def normalize_text(text):
    """æ¯”è¼ƒç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–"""
    text = re.sub(r'\s+', '', text)  # ç©ºç™½é™¤å»
    text = text.replace('ã€', '').replace('ã€‚', '')  # å¥èª­ç‚¹é™¤å»
    text = text.replace('ã€Œ', '').replace('ã€', '')  # æ‹¬å¼§é™¤å»
    text = text.replace('ï¼', '').replace('ï¼Ÿ', '')
    text = text.replace('â€¦', '').replace('......', '')
    return text

def find_differences(original, transcribed, chunk_num):
    """2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã®å·®åˆ†ã‚’æ¤œå‡º"""
    differences = []
    
    # æ–‡å˜ä½ã§æ¯”è¼ƒ
    orig_sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', original)
    trans_sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', transcribed)
    
    orig_sentences = [s.strip() for s in orig_sentences if s.strip()]
    trans_sentences = [s.strip() for s in trans_sentences if s.strip()]
    
    # å„åŸæ–‡ã«å¯¾ã—ã¦æœ€ã‚‚è¿‘ã„æ–‡å­—èµ·ã“ã—æ–‡ã‚’æ¢ã™
    for orig in orig_sentences:
        if len(orig) < 5:  # çŸ­ã™ãã‚‹æ–‡ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
            
        orig_norm = normalize_text(orig)
        best_match = None
        best_ratio = 0
        
        for trans in trans_sentences:
            trans_norm = normalize_text(trans)
            ratio = difflib.SequenceMatcher(None, orig_norm, trans_norm).ratio()
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = trans
        
        # 80%æœªæº€ã®ä¸€è‡´ç‡ãªã‚‰å·®åˆ†ã¨ã—ã¦è¨˜éŒ²
        if best_ratio < 0.95 and best_match:
            differences.append({
                'chunk': chunk_num,
                'original': orig,
                'transcribed': best_match,
                'ratio': best_ratio
            })
    
    return differences

all_differences = []

for i, (orig_chunk, trans_chunk) in enumerate(zip(chunks, transcribed_texts)):
    diffs = find_differences(orig_chunk, trans_chunk, i + 1)
    all_differences.extend(diffs)

# =============================================================================
# ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
# =============================================================================

print(f"\nğŸ“Š æ¤œå‡ºçµæœ: {len(all_differences)} ç®‡æ‰€ã®å·®ç•°")

report_path = os.path.join(OUTPUT_DIR, "reading_errors_report.txt")

with open(report_path, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("ğŸ“š TTSèª­ã¿é–“é•ã„æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ\n")
    f.write(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {INPUT_FILE}\n")
    f.write(f"éŸ³å£°: {TTS_VOICE} / ãƒ¢ãƒ‡ãƒ«: {TTS_MODEL}\n")
    f.write(f"æ¤œå‡ºæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write("=" * 80 + "\n\n")
    
    f.write(f"æ¤œå‡ºã•ã‚ŒãŸå·®ç•°: {len(all_differences)} ç®‡æ‰€\n\n")
    f.write("-" * 80 + "\n\n")
    
    for i, diff in enumerate(all_differences, 1):
        f.write(f"ã€{i}ã€‘ãƒãƒ£ãƒ³ã‚¯ {diff['chunk']} (ä¸€è‡´ç‡: {diff['ratio']*100:.1f}%)\n")
        f.write(f"  åŸæ–‡: {diff['original']}\n")
        f.write(f"  èªè­˜: {diff['transcribed']}\n")
        f.write("\n")

print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {report_path}")

# ç”»é¢ã«ã‚‚ä¸»è¦ãªå·®ç•°ã‚’è¡¨ç¤º
print("\n" + "=" * 70)
print("ğŸ” ä¸»ãªèª­ã¿é–“é•ã„å€™è£œï¼ˆä¸€è‡´ç‡90%æœªæº€ï¼‰")
print("=" * 70)

major_diffs = [d for d in all_differences if d['ratio'] < 0.9]

if major_diffs:
    for i, diff in enumerate(major_diffs[:20], 1):  # æœ€å¤§20ä»¶è¡¨ç¤º
        print(f"\nã€{i}ã€‘ä¸€è‡´ç‡: {diff['ratio']*100:.1f}%")
        print(f"  åŸæ–‡: {diff['original'][:50]}...")
        print(f"  èªè­˜: {diff['transcribed'][:50]}...")
else:
    print("\nâœ… å¤§ããªèª­ã¿é–“é•ã„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
print("\nğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...")
for audio_file in audio_files:
    try:
        os.remove(audio_file)
    except:
        pass

print("\n" + "=" * 70)
print("ğŸ‰ å‡¦ç†å®Œäº†ï¼")
print("=" * 70)
print(f"\nè©³ç´°ã¯ {report_path} ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
